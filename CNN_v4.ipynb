{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Concatenate, Dense, Input, concatenate\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_slices(path):\n",
    "    ind = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.split('.')[1] == 'txt':\n",
    "            ind.append(file.split('.')[0])\n",
    "        \n",
    "    df = pd.DataFrame(index = ind, columns= ['CT'])\n",
    "    for ind in df.index:\n",
    "        df.loc[ind].CT = np.loadtxt(path + ind + '.txt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_best_slices('best_lung_slice/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_data_all = pd.read_csv('patient_slope_intercept.csv', index_col=0)\n",
    "result = pd.DataFrame(index = df.index, columns = ['slope'])\n",
    "\n",
    "for ind in result.index:\n",
    "    result.loc[ind].slope = linear_data_all.loc[ind].slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for ind in df.index:\n",
    "    X.append(df.loc[ind].CT)\n",
    "\n",
    "X = np.array(X)/10\n",
    "X = X.reshape(X.shape[0], 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "y = result.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(y)\n",
    "y_scaled = scaler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer should be called on a list of at least 2 inputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8af9b736ce30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# Used purely for shape validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             raise ValueError('A `Concatenate` layer should be called '\n\u001b[0m\u001b[1;32m    350\u001b[0m                              'on a list of at least 2 inputs')\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer should be called on a list of at least 2 inputs"
     ]
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu', \n",
    "                 input_shape=(512,512,1), kernel_initializer='random_normal', \n",
    "                 bias_initializer='zeros' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 511, 511, 10)      50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 255, 255, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 253, 253, 10)      910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 126, 126, 10)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 126, 126, 10)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 158760)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1587610   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,588,691\n",
      "Trainable params: 1,588,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', metrics=['mean_squared_error'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "140/140 [==============================] - 9s 62ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 8s 58ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 8s 59ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 8s 57ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 8s 56ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f234833ba50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size=32, epochs=20, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.3214703],\n",
       "       [-5.0042615],\n",
       "       [-6.640951 ],\n",
       "       [-6.9929423],\n",
       "       [-5.936095 ],\n",
       "       [-5.2826657],\n",
       "       [-2.5023305],\n",
       "       [-6.5002594],\n",
       "       [-5.2864013],\n",
       "       [-5.141029 ],\n",
       "       [-3.7860622],\n",
       "       [-7.1335535],\n",
       "       [-4.7390203],\n",
       "       [-3.6418474],\n",
       "       [-5.6583247],\n",
       "       [-6.1442204],\n",
       "       [-5.455256 ],\n",
       "       [-2.5533507],\n",
       "       [-6.624594 ],\n",
       "       [-5.854339 ],\n",
       "       [-2.2301297],\n",
       "       [-2.6023266],\n",
       "       [-3.7801142],\n",
       "       [-5.3650274],\n",
       "       [-5.90843  ],\n",
       "       [-1.4496009],\n",
       "       [-3.7028086],\n",
       "       [-6.133801 ],\n",
       "       [-5.5570817],\n",
       "       [-5.589111 ],\n",
       "       [-5.2824535],\n",
       "       [-4.96003  ],\n",
       "       [-6.3055406],\n",
       "       [-1.1737467],\n",
       "       [-3.9894502],\n",
       "       [-6.650479 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.25292]]\n",
      "slope   -3.41031\n",
      "Name: ID00229637202260254240583, dtype: object\n"
     ]
    }
   ],
   "source": [
    "n=8\n",
    "example = df.iloc[n].CT.reshape(1,512,512,1)\n",
    "print(scaler.inverse_transform(model.predict(example)))\n",
    "print(result.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7031015758732995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scaler.inverse_transform(model.predict(X_test)) - scaler.inverse_transform(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.10365464],\n",
       "       [ -0.59836422],\n",
       "       [ -2.01667713],\n",
       "       [ -0.43741259],\n",
       "       [ -4.20860361],\n",
       "       [ -2.21685139],\n",
       "       [  9.05220839],\n",
       "       [ -2.90423317],\n",
       "       [ -4.26350233],\n",
       "       [ -0.57674104],\n",
       "       [ -3.44357802],\n",
       "       [-12.68318624],\n",
       "       [  0.35006384],\n",
       "       [ -2.28098694],\n",
       "       [ -0.0377488 ],\n",
       "       [ -7.4604788 ],\n",
       "       [ -6.40337866],\n",
       "       [ -6.04144002],\n",
       "       [ -4.54892513],\n",
       "       [ -2.33530229],\n",
       "       [ -1.4086339 ],\n",
       "       [  1.89659994],\n",
       "       [ -3.0797419 ],\n",
       "       [ -1.08055576],\n",
       "       [ 14.68261173],\n",
       "       [  0.59778705],\n",
       "       [ -4.44100719],\n",
       "       [ -4.18569593],\n",
       "       [-16.46481705],\n",
       "       [ -4.51304901],\n",
       "       [ -5.87359531],\n",
       "       [ -5.49436856],\n",
       "       [ -2.3159204 ],\n",
       "       [ -2.83713956],\n",
       "       [ -5.73331844],\n",
       "       [ -7.61721992]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
