{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Concatenate, Dense, Input, concatenate\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_slices(path):\n",
    "    ind = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.split('.')[1] == 'txt':\n",
    "            ind.append(file.split('.')[0])\n",
    "        \n",
    "    df = pd.DataFrame(index = ind, columns= ['CT'])\n",
    "    for ind in df.index:\n",
    "        df.loc[ind].CT = np.loadtxt(path + ind + '.txt')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_best_slices('best_lung_slice/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_data_all = pd.read_csv('patient_slope_intercept.csv', index_col=0)\n",
    "result = pd.DataFrame(index = df.index, columns = ['slope'])\n",
    "\n",
    "for ind in result.index:\n",
    "    result.loc[ind].slope = linear_data_all.loc[ind].slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for ind in df.index:\n",
    "    X.append(df.loc[ind].CT)\n",
    "\n",
    "X = np.array(X)/10\n",
    "X = X.reshape(X.shape[0], 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "y = result.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(y)\n",
    "y_scaled = scaler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu', \n",
    "                 input_shape=(512,512,1), kernel_initializer='random_normal', \n",
    "                 bias_initializer='zeros' ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', metrics=['mean_squared_error'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train, batch_size=32, epochs=20, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=8\n",
    "example = df.iloc[n].CT.reshape(1,512,512,1)\n",
    "print(scaler.inverse_transform(model.predict(example)))\n",
    "print(result.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(scaler.inverse_transform(model.predict(X_test)) - scaler.inverse_transform(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
